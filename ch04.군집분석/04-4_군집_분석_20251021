{"cells":[{"cell_type":"markdown","source":["## 1\\. 군집모형 성능 평가\n","\n","  - **문제 제기**: 마케팅 팀이 K-Means로 나눈 고객 그룹이 얼마나 정확한지, 기존 우수 고객 명단과 얼마나 일치하는지 어떻게 평가할 수 있을까?\n","  - **필요성**: 군집 분석은 정답 없는 데이터를 탐색하는 도구지만, 때로는 비교할 수 있는 '정답' 혹은 '기준'이 있을 수 있음. 이럴 때 군집화 결과가 기준에 얼마나 부합하는지 객관적인 '점수'로 평가할 필요가 있음.\n","  - **학습 목표**: 군집 모델이 만들어 낸 그룹이 실제 데이터의 구조나 정답과 얼마나 유사한지를 측정하는 다양한 **성능 평가 지표**를 학습하고, 이를 통해 모델 성능을 비교하거나 최적의 클러스터 개수를 찾는 등 데이터 기반 의사결정을 내림.\n","\n","-----\n","\n","## 2\\. 핵심 원리 파헤치기 (Deep Dive)\n","\n","  - **핵심 차이점**: 군집 알고리즘이 부여한 레이블(예: 0, 1, 2)은 실제 레이블(예: '사과', '바나나')과 이름 자체는 관련이 없음.\n","  - **본질적 질문**: \"같은 그룹에 속해야 할 데이터들이 실제로 같은 그룹에 묶였는가?\"\n","\n","### 1\\. 랜드 지수 (Rand Index, RI)\n","\n","  - **`랜드 지수(Rand Index)`**: 두 군집화 결과(모델 예측 U, 실제 정답 V)가 얼마나 일치하는지 평가하는 직관적인 방법.\n","  - **'사진 분류' 비유**: 당신(U)과 친구(V)가 사진을 분류한 결과를 비교. 무작위로 사진 두 장을 뽑아봄.\n","      - **a (일치)**: 둘 다 두 사진을 '같은' 폴더에 넣음.\n","      - **b (일치)**: 둘 다 두 사진을 '다른' 폴더에 넣음.\n","      - **c, d (불일치)**: 한 명은 '같은' 폴더에, 다른 한 명은 '다른' 폴더에 넣음.\n","      - 랜드 지수는 전체 사진 쌍 중 **일치한 경우(a+b)의 비율**임.\n","\n","| 상황 | 설명                               | 쌍 개수 | 의미                 |\n","| -- | -------------------------------- | ---- | ------------------ |\n","| a  | 둘 다 ‘같은 폴더’로 분류                  | (a)  | TP (True Positive) |\n","| b  | 둘 다 ‘다른 폴더’로 분류                  | (b)  | TN (True Negative) |\n","| c  | 한쪽만 ‘같은 폴더’로, 다른 한쪽은 ‘다른 폴더’로 분류 | (c)  | FN                 |\n","| d  | 반대 상황                            | (d)  | FP                 |\n","\n","\n","  - **랜드 지수 공식**:\n","$$RI = \\frac{a+b}{a+b+c+d} = \\frac{a+b}{\\binom{n}{2}}$$\n","      - 분모는 전체 데이터에서 2개의 쌍을 뽑는 모든 경우의 수, 분자는 두 군집화 결과가 일치하는 쌍의 개수.\n","      - 0과 1 사이의 값을 가지며, 1에 가까울수록 완벽하게 일치함을 의미.\n","\n","### 2\\. 조정된 랜드 지수 (Adjusted Rand Index, ARI)\n","\n","  - **랜드 지수의 함정**: 클러스터 수가 많아지면 우연히 '다른 클러스터에 속하는' 쌍(b)의 수가 늘어나 점수가 높아지는 경향이 있음.\n","  - **`조정된 랜드 지수(ARI)`**: 이러한 **우연(chance)에 의한 점수 상승을 보정**해주는 지표.\n","  - **장점**: 두 군집화 결과가 무작위일 경우 0, 완벽하게 일치할 경우 1의 점수를 갖도록 조정됨. 따라서 클러스터 개수가 다른 모델들을 비교할 때 일반 RI보다 훨씬 신뢰할 수 있음.\n","\n","$$ ARI = \\frac{RI - E[RI]}{1 - E[RI]} $$\n","\n","\n","$$ ARI = \\frac{ \\mathrm{Index} - \\mathbb{E}[\\mathrm{Index}] }{ \\mathrm{MaxIndex} - \\mathbb{E}[\\mathrm{Index}] } $$\n","\n","\n","$$\n","ARI =\n","\\frac{\\sum_{i,j} \\binom{n_{ij}}{2} - \\frac{\\left(\\sum_i \\binom{a_i}{2}\\right)\\left(\\sum_j \\binom{b_j}{2}\\right)}{\\binom{n}{2}}}\n","{\\frac{1}{2}\\left(\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2}\\right) - \\frac{\\left(\\sum_i \\binom{a_i}{2}\\right)\\left(\\sum_j \\binom{b_j}{2}\\right)}{\\binom{n}{2}} }\n","$$\n","    \n","\n","### 3\\. 그 외의 주요 평가 지표들\n","\n","  - **조정된 상호 정보량 (Adjusted Mutual Information, AMI)**: 한 군집화 결과가 다른 군집화 결과에 대해 얼마나 많은 정보를 담고 있는지 측정. 우연에 대해 보정된 값 (0\\~1).\n","  - **포울크스-멜로우 지수 (Fowlkes-Mallows Index, FMI)**: 정밀도와 재현율의 기하 평균. 값이 높을수록 두 군집이 유사함.\n","  - **Homogeneity, Completeness, V-measure**:\n","      - **`Homogeneity`**: 각 클러스터가 얼마나 단일 클래스의 데이터로만 구성되었는지 측정 (0\\~1).\n","      - **`Completeness`**: 같은 클래스에 속한 데이터들이 얼마나 같은 클러스터에 모여 있는지 측정 (0\\~1).\n","      - **`V-measure`**: Homogeneity와 Completeness의 조화 평균 (0\\~1).\n","\n","-----\n","\n","## 3\\. 실전 코드 분석 및 적용 (Code Walkthrough & Application)\n","\n","### 1\\. Scikit-learn의 평가 지표 확인하기"],"metadata":{"id":"9Yi9reBxB-xq"}},{"cell_type":"code","source":["# Scikit-learn에서 제공하는 전체 평가 지표 키를 확인합니다.\n","from sklearn.metrics import get_scorer_names\n","\n","get_scorer_names()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["['accuracy',\n"," 'adjusted_mutual_info_score',\n"," 'adjusted_rand_score',\n"," 'average_precision',\n"," 'balanced_accuracy',\n"," 'completeness_score',\n"," 'd2_absolute_error_score',\n"," 'explained_variance',\n"," 'f1',\n"," 'f1_macro',\n"," 'f1_micro',\n"," 'f1_samples',\n"," 'f1_weighted',\n"," 'fowlkes_mallows_score',\n"," 'homogeneity_score',\n"," 'jaccard',\n"," 'jaccard_macro',\n"," 'jaccard_micro',\n"," 'jaccard_samples',\n"," 'jaccard_weighted',\n"," 'matthews_corrcoef',\n"," 'mutual_info_score',\n"," 'neg_brier_score',\n"," 'neg_log_loss',\n"," 'neg_max_error',\n"," 'neg_mean_absolute_error',\n"," 'neg_mean_absolute_percentage_error',\n"," 'neg_mean_gamma_deviance',\n"," 'neg_mean_poisson_deviance',\n"," 'neg_mean_squared_error',\n"," 'neg_mean_squared_log_error',\n"," 'neg_median_absolute_error',\n"," 'neg_negative_likelihood_ratio',\n"," 'neg_root_mean_squared_error',\n"," 'neg_root_mean_squared_log_error',\n"," 'normalized_mutual_info_score',\n"," 'positive_likelihood_ratio',\n"," 'precision',\n"," 'precision_macro',\n"," 'precision_micro',\n"," 'precision_samples',\n"," 'precision_weighted',\n"," 'r2',\n"," 'rand_score',\n"," 'recall',\n"," 'recall_macro',\n"," 'recall_micro',\n"," 'recall_samples',\n"," 'recall_weighted',\n"," 'roc_auc',\n"," 'roc_auc_ovo',\n"," 'roc_auc_ovo_weighted',\n"," 'roc_auc_ovr',\n"," 'roc_auc_ovr_weighted',\n"," 'top_k_accuracy',\n"," 'v_measure_score']"]},"metadata":{},"execution_count":1}],"execution_count":1,"metadata":{"id":"irHbs77IB-xu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761024184884,"user_tz":-540,"elapsed":3189,"user":{"displayName":"이정현","userId":"07909459242714302283"}},"outputId":"0c141b69-508d-490b-a983-48a79f22363f"}},{"cell_type":"markdown","source":["- **코드 해설**: 이 목록에는 회귀, 분류, 군집 분석을 위한 다양한 평가 지표가 포함되어 있으며, **`'adjusted_rand_score'`**, **`'homogeneity_score'`** 등이 군집 분석에 사용되는 지표임.\n","\n","### 2\\. 랜드 지수(Rand Index) 직접 구현 및 계산"],"metadata":{"id":"xb3DTTjYB-xv"}},{"cell_type":"code","source":["# 랜드 지수를 직접 계산하는 함수를 정의합니다.\n","def rand_index(y_true, y_pred):\n","    n = len(y_true) # 데이터의 총 개수\n","    a, b = 0, 0 # a와 b 변수 초기화\n","\n","    # 모든 데이터 쌍(pair)을 순회합니다.\n","    for i in range(n):\n","        for j in range(i + 1, n):\n","            # case 'a': 두 군집화 결과 모두에서 같은 클러스터에 속하는 경우\n","            if (y_true[i] == y_true[j]) & (y_pred[i] == y_pred[j]):\n","                a += 1\n","            # case 'b': 두 군집화 결과 모두에서 다른 클러스터에 속하는 경우\n","            elif (y_true[i] != y_true[j]) & (y_pred[i] != y_pred[j]):\n","                b += 1\n","            else:\n","                pass # 그 외의 경우는 세지 않음\n","\n","    # 랜드 지수 공식을 적용하여 RI를 계산합니다.\n","    RI = (a + b) / (n * (n - 1) / 2)\n","    return RI"],"outputs":[],"execution_count":2,"metadata":{"id":"59QrYvhCB-xv","executionInfo":{"status":"ok","timestamp":1761024272168,"user_tz":-540,"elapsed":40,"user":{"displayName":"이정현","userId":"07909459242714302283"}}}},{"cell_type":"code","source":["# 필요한 라이브러리를 임포트합니다.\n","import seaborn as sns\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import LabelEncoder\n","\n","# iris 데이터셋을 로드합니다.\n","iris = sns.load_dataset(\"iris\")\n","\n","# 특성 데이터(X)와 정답 레이블(y)을 분리합니다.\n","iris_X = iris.iloc[:, :-1]\n","iris_y = iris.species\n","\n","# K-Means 모델을 생성하고 학습시킵니다 (클러스터 수 k=3).\n","iris_cluster_model = KMeans(n_clusters=3, random_state=1)\n","iris_cluster_model.fit(iris_X)\n","\n","# K-Means가 예측한 클러스터 레이블(0, 1, 2)을 실제 품종 레이블 순서와 맞추기 위해 재조정합니다.\n","# 주의: 이 과정은 실제 분석에서는 필요 없을 수 있으며, 어떤 클러스터가 어떤 품종에 해당하는지 알 수 없기 때문입니다.\n","# 여기서는 평가를 위해 임의로 맞추는 과정입니다.\n","pred = np.choose(iris_cluster_model.labels_, [1, 0, 2])\n","\n","# 문자열로 된 실제 품종 레이블을 숫자(0, 1, 2)로 변환합니다.\n","le = LabelEncoder()\n","le.fit(iris.species)\n","predict = le.inverse_transform(pred) # 숫자 레이블을 다시 품종 이름으로 변환\n","\n","# 직접 구현한 랜드 지수 함수를 호출하여 점수를 확인합니다.\n","rand_index(y_true=iris.species, y_pred=predict)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8737360178970918"]},"metadata":{},"execution_count":3}],"execution_count":3,"metadata":{"id":"feMBacqsB-xv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761024309864,"user_tz":-540,"elapsed":1716,"user":{"displayName":"이정현","userId":"07909459242714302283"}},"outputId":"71624a6b-3d8c-4534-9496-1cdd00324547"}},{"cell_type":"markdown","source":["- **코드 해설**: `iris` 데이터의 실제 품종이 3개이므로 K-Means의 \\*\\*`n_clusters`\\*\\*를 3으로 설정함. **`rand_index`** 계산 결과 약 0.88로, K-Means 군집화 결과가 실제 품종 분류와 상당히 일치함을 의미함.\n","\n","### 3\\. 클러스터 개수를 바꿔서 비교하기"],"metadata":{"id":"A-fGPRCFB-xw"}},{"cell_type":"code","source":["# K-Means 모델을 클러스터 2개로 다시 학습시킵니다.\n","iris_cluster_model = KMeans(n_clusters=2, random_state=1)\n","iris_cluster_model.fit(iris_X)\n","\n","# 정답 레이블을 생성합니다: setosa는 1, 나머지(versicolor, virginica)는 0으로 설정\n","y_true = [1]*50 + [0]*100\n","\n","# 랜드 지수를 계산합니다.\n","rand_index(y_true, iris_cluster_model.labels_)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9605369127516779"]},"metadata":{},"execution_count":4}],"execution_count":4,"metadata":{"id":"eT2zw-tDB-xw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761024345226,"user_tz":-540,"elapsed":55,"user":{"displayName":"이정현","userId":"07909459242714302283"}},"outputId":"f6f80812-93f1-45a3-930d-fbf27bfa9595"}},{"cell_type":"markdown","source":["- **코드 해설**: 클러스터를 2개로 설정했을 때 랜드 지수가 약 0.96으로 더 높게 나왔음. 이는 RI가 클러스터 수에 영향을 받으므로 완벽한 비교는 아님.\n","\n","### 4\\. Scikit-learn의 다양한 평가 지표 사용하기\n","\n","  - 우연을 보정한 `Adjusted Rand Index (ARI)`와 다른 지표들을 계산. 이 함수들은 레이블을 수동으로 재조정할 필요가 없어 편리함.\n","\n","<!-- end list -->"],"metadata":{"id":"0S2okzO5B-xw"}},{"cell_type":"code","source":["from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, fowlkes_mallows_score, homogeneity_score, completeness_score, v_measure_score\n","\n","# 이전 단계에서 k=3으로 군집화한 예측 결과 'predict'를 사용합니다.\n","\n","# 조정된 랜드 지수 (ARI)\n","ari_score = adjusted_rand_score(labels_true=iris.species, labels_pred=predict)\n","print(f\"Adjusted Rand Index: {ari_score}\")\n","\n","# 조정된 상호 정보량 (AMI)\n","ami_score = adjusted_mutual_info_score(labels_true=iris.species, labels_pred=predict)\n","print(f\"Adjusted Mutual Info Score: {ami_score}\")\n","\n","# 포울크스-멜로우 지수 (FMI)\n","fmi_score = fowlkes_mallows_score(labels_true=iris.species, labels_pred=predict)\n","print(f\"Fowlkes-Mallows Score: {fmi_score}\")\n","\n","# Homogeneity, Completeness, V-measure\n","h_score = homogeneity_score(labels_true=iris.species, labels_pred=predict)\n","c_score = completeness_score(labels_true=iris.species, labels_pred=predict)\n","v_score = v_measure_score(labels_true=iris.species, labels_pred=predict)\n","print(f\"Homogeneity Score: {h_score}\")\n","print(f\"Completeness Score: {c_score}\")\n","print(f\"V-measure Score: {v_score}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusted Rand Index: 0.7163421126838476\n","Adjusted Mutual Info Score: 0.7386548254402864\n","Fowlkes-Mallows Score: 0.8112427991975698\n","Homogeneity Score: 0.7364192881252849\n","Completeness Score: 0.7474865805095324\n","V-measure Score: 0.7419116631817836\n"]}],"execution_count":5,"metadata":{"id":"Ko9mQ-SfB-xx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761024563293,"user_tz":-540,"elapsed":29,"user":{"displayName":"이정현","userId":"07909459242714302283"}},"outputId":"2597669e-81d9-4eaa-acef-d07e16b64d30"}},{"cell_type":"markdown","source":["- **코드 해설**: 다양한 지표를 통해 군집 모델의 성능을 다각도로 평가할 수 있음. **ARI 점수**는 약 0.73으로, 무작위 추측(0)보다는 훨씬 좋지만 완벽한(1) 수준은 아님을 보여줌. 여러 지표를 함께 확인하여 모델 성능을 종합적으로 판단하는 것이 좋음.\n","\n","-----\n","\n","## 4\\. 핵심 요약 (Key Takeaways)\n","\n","  - **비즈니스 관점**: 군집 분석 결과를 기존의 '정답' 데이터와 비교하여, 군집 모델이 **비즈니스적으로 의미 있는 패턴**을 찾아냈는지 객관적으로 검증 가능함.\n","  - **기술 관점**: 단순 \\*\\*`랜드 지수(RI)`\\*\\*는 클러스터 개수에 따라 점수가 왜곡될 수 있으므로, 우연에 의한 효과를 보정한 \\*\\*`조정된 랜드 지수(ARI)`\\*\\*나 \\*\\*`조정된 상호 정보량(AMI)`\\*\\*을 사용하는 것이 훨씬 신뢰성이 높음.\n","  - **해석 관점**: 군집 성능 평가 지표는 대부분 0과 1 사이의 값을 가짐. 점수가 **1에 가까울수록** 군집 결과가 실제 레이블과 완벽하게 일치하며, **0에 가까울수록** 무작위 분류와 차이가 없음을 의미함."],"metadata":{"id":"LAIZZw9sB-xx"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}